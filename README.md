# Adaptive Intervention Mechanism (AIM)

<h3><b>ICML 2025</b></h3>

Official release for the code used in the paper: *Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism*

[**Webpage**](https://metadriverse.github.io/aim/) | 
[**Code**](https://github.com/metadriverse/aim) |
[**Paper**](https://arxiv.org/pdf/2506.09176)

[![](https://github.com/metadriverse/AIM/blob/main/teaser.png)](https://metadriverse.github.io/aim/)

## Installation

```bash
git clone https://github.com/metadriverse/aim
cd AIM

# Create Conda environment
conda create -n aim python=3.7
conda activate aim

# Install dependencies
pip install -r requirements.txt
pip install -e .
```

## Launch Experiments

### MetaDrive

In MetaDrive, we use a well-trained PPO neural expert to approximate human policies generated by the script `train_ppo_metadrive.py`. We provide a pretrained PPO expert in `aim/experiments/metadrive/metadrive_ppo_20m_steps.zip`.

To reproduce the main experiment reported in the paper, run the training script `train_aim_metadrive.py` in the folder `aim/experiments/metadrive`. The main experiment of AIM takes about 10 minutes. We also provide a simpler toy environment with `--toy_env`.

You can also specify an intended switch-to-human frequency `SWITCH_RATE` and initial warm-up steps `WARMUP_STEPS`, depending on your budget of expert involvement. The default `SWITCH_RATE` is 0.05, and the default `WARMUP_STEPS` is 200. 

```bash
cd ~/AIM

# Train PPO expert (Skip this if you want)
python aim/experiments/metadrive/train_ppo_metadrive.py \
--exp_name ppo_metadrive

# Run toy experiment
python aim/experiments/metadrive/train_aim_metadrive.py \
--exp_name aim_metadrive_toy \
--toy_env

# Run full experiment
python aim/experiments/metadrive/train_aim_metadrive.py \
--exp_name aim_metadrive \
--wandb \
--wandb_project WADNB_PROJECT_NAME \
--wandb_team WANDB_ENTITY_NAME \
--delta SWITCH_RATE \
--init_bc_steps WARMUP_STEPS
```

### Minigrid
In Minigrid, we provide a pretrained neural expert in `aim/experiments/minigrid/best_model_minigrid_4roomlarge.zip` to approximate human policies. The training script `train_aim_minigrid.py` trains AIM in the Minigrid multi-room environment.
```bash
cd ~/AIM
python aim/experiments/minigrid/train_aim_minigrid.py \
--exp_name aim_minigrid \
--wandb \
--wandb_project WADNB_PROJECT_NAME \
--wandb_team WANDB_ENTITY_NAME
```

## References

```latex
@article{cai2025robot,
  title={Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism},
  author={Cai, Haoyuan and Peng, Zhenghao and Zhou, Bolei},
  journal={International Conference on Machine Learning},
  year={2025}
}
```
